{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting to gray-scale \n",
    "grayscale_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing=mediapipe.solutions.drawing_utils\n",
    "mp_drawing_style=mediapipe.solutions.drawing_styles\n",
    "\n",
    "drawing_specs=mp_drawing.DrawingSpec(color=(0,0,0),thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Shades overlay area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSize(image, face_landmarks):\n",
    "    # Retrieve the height and width of the image.\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Convert the indexes of the landmarks of the face part into a list.\n",
    "    INDEXES_LIST = [130,263]\n",
    "\n",
    "    # Initialize a list to store the landmarks of the face part.\n",
    "    landmarks = []\n",
    "\n",
    "    # Iterate over the indexes of the landmarks of the face part. \n",
    "    for INDEX in INDEXES_LIST:\n",
    "        # Append the landmark into the list.\n",
    "        landmarks.append([int(face_landmarks[0].landmark[INDEX].x * image_width), int(face_landmarks[0].landmark[INDEX].y * image_height)])\n",
    "\n",
    "    # Calculate the width and height of the face part.\n",
    "    _, _, width, height = cv2.boundingRect(np.array(landmarks))\n",
    "\n",
    "    # # Convert the list of landmarks of the face part into a numpy array.\n",
    "    landmarks = np.array(landmarks)\n",
    "\n",
    "    return width,height,landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(image, filter_image, face_landmarks): \n",
    "    annotated_image = image.copy()\n",
    "    \n",
    "    try:\n",
    "        # Get the width and height of filter image.\n",
    "        filter_img_height, filter_img_width,_  = filter_image.shape\n",
    " \n",
    "        # Get the height of the face part on which we will overlay the filter image.\n",
    "        _, face_part_height,landmarks = getSize(image, face_landmarks)\n",
    "        \n",
    "        # Specify the height to which the filter image is required to be resized.\n",
    "        required_height = int(face_part_height*15)\n",
    "        \n",
    "        # Resize the filter image to the required height, while keeping the aspect ratio constant. \n",
    "        resized_filter_img = cv2.resize(filter_image, (int(filter_img_width//3),required_height))\n",
    "        \n",
    "        # Get the new width and height of filter image.\n",
    "        filter_img_height, filter_img_width, _  = resized_filter_img.shape\n",
    " \n",
    "        # Convert the image to grayscale and apply the threshold to get the mask image.\n",
    "        _, filter_img_mask = cv2.threshold(cv2.cvtColor(resized_filter_img, cv2.COLOR_BGR2GRAY),25, 255, cv2.THRESH_BINARY_INV)\n",
    " \n",
    "        # Calculate the center of the face part.\n",
    "        center = landmarks.mean(axis=0).astype(\"int\")\n",
    " \n",
    "        # calcualte the position to place the glasses\n",
    "        location = (int(center[0]-filter_img_width/2), int(center[1]-filter_img_height/2))\n",
    " \n",
    "        # Retrieve the region of interest from the image where the filter image will be placed.\n",
    "        ROI = image[location[1]: location[1] + filter_img_height,location[0]: location[0] + filter_img_width]\n",
    " \n",
    "        # Perform Bitwise-AND operation. This will set the pixel values of the region where,\n",
    "        # filter image will be placed to zero.\n",
    "        resultant_image = cv2.bitwise_and(ROI, ROI, mask=filter_img_mask)\n",
    " \n",
    "        # Add the resultant image and the resized filter image.\n",
    "        # This will update the pixel values of the resultant image at the indexes where \n",
    "        # pixel values are zero, to the pixel values of the filter image.\n",
    "        resultant_image = cv2.add(resultant_image, resized_filter_img)\n",
    " \n",
    "        # Update the image's region of interest with resultant image.\n",
    "        annotated_image[location[1]: location[1] + filter_img_height, location[0]: location[0] + filter_img_width] = resultant_image\n",
    "            \n",
    "    # Catch and handle the error(s).\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing video frame\n",
    "vdf=cv2.VideoCapture(0)\n",
    "shades=cv2.imread('shades.png')\n",
    "\n",
    "face_mesh_model=mediapipe.solutions.face_mesh\n",
    "\n",
    "with face_mesh_model.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks= True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence =0.5\n",
    ") as face_mesh:\n",
    "    \n",
    "    while vdf.isOpened():\n",
    "        success,image=vdf.read()\n",
    "    \n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        results=face_mesh.process(image)\n",
    "        new_image=overlay(image,shades, results.multi_face_landmarks)\n",
    "            \n",
    "        cv2.imshow(\"Camera\",cv2.flip(new_image,1))\n",
    "\n",
    "        if cv2.waitKey(10)== ord('x'):\n",
    "            break\n",
    "\n",
    "vdf.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def is_face_tilted(face_landmarks):\n",
    "    # Assuming face_landmarks is a dictionary or list containing coordinates of facial landmarks\n",
    "    # For example, if using dlib's facial landmarks, face_landmarks could be a shape object.\n",
    "\n",
    "    # Extract eye landmarks (you may need to adjust these indices based on the specific landmarks you have)\n",
    "    left_eye = np.array(face_landmarks[36:42])  # left eye landmarks\n",
    "    right_eye = np.array(face_landmarks[42:48])  # right eye landmarks\n",
    "\n",
    "    # Calculate the angle between the eyes\n",
    "    angle = calculate_angle_between_eyes(left_eye, right_eye)\n",
    "\n",
    "    # Define a threshold to determine if the face is tilted\n",
    "    tilt_threshold = 10  # Adjust this threshold based on your requirements\n",
    "\n",
    "    # Check if the angle is beyond the threshold\n",
    "    return abs(angle) > tilt_threshold\n",
    "\n",
    "def calculate_angle_between_eyes(left_eye, right_eye):\n",
    "    # Calculate the angle between the line connecting eye landmarks\n",
    "    # This function assumes the eye landmarks are ordered (x, y)\n",
    "\n",
    "    # Calculate vectors representing the lines connecting the eyes\n",
    "    vector_left = left_eye[-1] - left_eye[0]\n",
    "    vector_right = right_eye[-1] - right_eye[0]\n",
    "\n",
    "    # Calculate the cosine of the angle between the vectors\n",
    "    dot_product = np.dot(vector_left, vector_right)\n",
    "    magnitude_left = np.linalg.norm(vector_left)\n",
    "    magnitude_right = np.linalg.norm(vector_right)\n",
    "\n",
    "    # Ensure denominator is not zero\n",
    "    if magnitude_left * magnitude_right == 0:\n",
    "        return 0\n",
    "\n",
    "    cosine_angle = dot_product / (magnitude_left * magnitude_right)\n",
    "\n",
    "    # Calculate the angle in degrees\n",
    "    angle = np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON UI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run\n",
    "pip install wxpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-18.04/\n",
      "Requirement already satisfied: wxPython in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (4.2.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from wxPython) (10.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from wxPython) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from wxPython) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U -f https://extras.wxpython.org/wxPython4/extras/linux/gtk3/ubuntu-18.04/ wxPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "import wx\n",
    "\n",
    "app = wx.App()\n",
    "frame = wx.Frame(parent=None, title='Face Filter')\n",
    "frame.Show()\n",
    "app.MainLoop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
